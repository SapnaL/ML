{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Machine Learning - Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now apply unsupervised learning to our King's County, Washington home sale data.  As a reminder, unsupervised techniques aren't meant to predict values or classifications, but rather to understand the intrinsic structure or identify outliers.  Here, we will do both.  As we previously did, we need to do our imports, read our data in and check it, and drop any columns we don't need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the regression tasks of our last lab, the true price value was okay since the algorithm only cared that the input values were on the same scale (which is why we normalized the values).  Now, we also need to scale the price column.  We will again use the ``MinMaxScaler``, but only on the price column.  Perform the fit and transform the column.  You'll notice that we have already pulled the values for the price and applied ``.reshape(-1,1)``.  This is because we need to tell the scaler that these are all related data columns.  Otherwise, it could mistakenly think this is a single row of many columns, so we need to explicitly format in the desired configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = \n",
    "df['price'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickly check that we actually did what we wanted to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data looks correct, let's start by fitting a k-means model.  We want to fit to get the correct number of clusters, but the first step is to make sure we can get it to work.  Begin by setting up a k-means model with 3 clusters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the fit model, call the ``.interia`` attribute to get the sum of squared distances to their closest cluster center.  As a performance metric, this is similar to the mean squared error we used in the supervised regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this working, we now want to wrap these steps into a loop to step through a range of cluster numbers and track how the sum of the squared distances changes.  We can then determine how many clusters are present in the data by using the \"elbow\" method to see where the rate of the distance improvement begins to decline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distance measure vs the cluster number.  To make a plot like we saw in the lecture, you can change the linestyle to ``'.-'`` and then the ``linewidth`` and ``markersize`` parameters in Matplotlib's ``plot`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the curve appear and how well-defined is the elbow?  Jot down some notes of your observations and your thoughts about what this is telling us about the data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elbow curve notes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a second validation, let's use the silhouette score.  This metric measures the uniqueness of clusters by calculating the distance of points in one cluster to those in a neighboring cluster.  The metric takes on values between -1 and 1, with negative values meaning points are assigned to the wrong cluster, zero meaning they are overlapping, and closer to positive 1 meaning maximally distinct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we just did for the distance, we want to calculate the score for each loop and make a plot.  However, we first want to just get familiar with the functionality by running it on a single test case.  Construct a k-means model using the cluster number of your choosing, make predictions using the ``fit_predict`` method, and then calculate the silhoutte score.  The consistency of the Sci-kit Learn API makes using the ``fit_predict`` method easy, but you may need to look up how to call the ``silhouette_score`` function and what you need to pass it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "kmeans = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a single silhouette score has been calculated, wrap it in a loop and then plot the silhouette score vs. the number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move to the more sophisticated DBSCAN model.  DBSCAN offers many benefits for clustering applications because it finds the cluster number by itself and it also identifies outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's define a model.  We can define several hyperparameters including the maximum distance between samples in a cluster (the ``eps`` parameter) and the minimum number of samples to define a cluster (``min_samples``).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "db = DBSCAN(eps=0.25, min_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit the model on data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this fit model, pull out the labels so we can perform some calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the labels in a list, we can count the number of clusters and the number of points considered \"noise.\"  By default, DBSCAN labels outliers as ``-1``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cluster Number:  ', )\n",
    "print('Outlier Number:  ', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the silhouette score to see if this is improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Silhouette Score:  ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The isolation forest identifies outliers by randomly slicing your dataset and determining how easy it is to separate points from the bulk of the data.  Let's begin by defining the model.  Like the random forest model, choose a large-ish value for the ``n_estimators`` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "if_model = IsolationForest(n_estimators= , behaviour='new', contamination='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the ``fit_predict`` function, fit the isolation forest and assign labels (outlier or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to  count how many outliers the model identifies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's conclude by taking a look at the outliers and seeing if there are certain prices where sells that are considered anomalies can be found.  The ease with which we can plot histograms makes this fairly straightforward once the data is in the right form.  Since we normalized the values with the ``MinMaxScaler`` we have to undo this transformation with ``inverse_transform``.  We've pulled the data and gotten it into the right form so you can the transform below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_price_data_scaled = df['price'].values.reshape(-1, 1)\n",
    "anomaly_price_data_scaled = df[df['labels']==-1]['price'].values.reshape(-1, 1)\n",
    "\n",
    "full_price_data = \n",
    "anomaly_price_data = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How use Seaborn to plot the distributions and see how they compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you conclude about the frequency of outliers and the relation to price?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
